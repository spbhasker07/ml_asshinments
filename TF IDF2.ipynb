{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57867a83-b0af-4da6-b2ff-93da2720b8b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Feature Extraction using CountVecterizer & TFIDFVectorizer :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdc0e09f-3052-4a4a-b3c6-81fbbf65d5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1='f5o@od is # good & good!'\n",
    "doc2='food is tasty'\n",
    "doc3='Quality is Good'\n",
    "doc4='food is not good'\n",
    "doc5='Servi89ce is poor'\n",
    "doc6='it is to_o costly'\n",
    "doc7='Che^ap quality'\n",
    "\n",
    "corpus=[doc1,doc2,doc3,doc4,doc5,doc6,doc7]\n",
    "target=['pos','pos','pos','neg','neg','neg','neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "562e3356-e477-4da6-803e-1f6d90888dcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba448032-dfa7-4361-aded-73b6140fef66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318\n"
     ]
    }
   ],
   "source": [
    "sw=list(ENGLISH_STOP_WORDS)\n",
    "print(len(sw))\n",
    "sw.remove(\"not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c739689c-067b-4295-9b01-b5877a90530f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def text_cleaning(doc):\n",
    "    doc=doc.lower()\n",
    "    doc=re.sub('[^a-zA-Z ]','',doc)\n",
    "    tokens=doc.split()\n",
    "    newdoc=\"\"\n",
    "    for token in tokens:\n",
    "        if token not in sw:\n",
    "            newdoc=newdoc+token+\" \"\n",
    "    return newdoc.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6b52ae8-c3a2-4b93-95eb-0b8b6935aef3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_corpus=list(map(text_cleaning,corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5749314-3265-4120-b14d-2171c97506a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['food good good',\n",
       " 'food tasty',\n",
       " 'quality good',\n",
       " 'food not good',\n",
       " 'service poor',\n",
       " 'costly',\n",
       " 'cheap quality']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96906439-9ed3-4fe0-896e-64323e75453e",
   "metadata": {},
   "source": [
    "### Feature Extraction\n",
    "- process of extracting features from corpus\n",
    "- sklearn provides 2 approaches\n",
    "  - CountVectorizer\n",
    "  - TfidfVectorizer\n",
    "### Vectorization\n",
    "- process of converting a document into array of numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e734fb10-a255-4275-8b55-cbe7afabe39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b318e36-cac0-485b-9526-2ddf3d569bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t1\n",
      "  (0, 3)\t2\n",
      "  (1, 2)\t1\n",
      "  (1, 8)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 6)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 3)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 7)\t1\n",
      "  (4, 5)\t1\n",
      "  (5, 1)\t1\n",
      "  (6, 6)\t1\n",
      "  (6, 0)\t1\n"
     ]
    }
   ],
   "source": [
    "cv=CountVectorizer()\n",
    "X=cv.fit_transform(final_corpus) #extract features as well as perform vectorization\n",
    "print(X)           #sparse matrix representation of vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b64582a-08d6-4ef0-aada-6ee905b3707a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cheap' 'costly' 'food' 'good' 'not' 'poor' 'quality' 'service' 'tasty']\n",
      "[[0 0 1 2 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 1]\n",
      " [0 0 0 1 0 0 1 0 0]\n",
      " [0 0 1 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 1 0]\n",
      " [0 1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 1 0 0]]\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t2\n",
      "  (1, 2)\t1\n",
      "  (1, 8)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 6)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 3)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 7)\t1\n",
      "  (4, 5)\t1\n",
      "  (5, 1)\t1\n",
      "  (6, 6)\t1\n",
      "  (6, 0)\t1\n"
     ]
    }
   ],
   "source": [
    "cv=CountVectorizer()\n",
    "X=cv.fit_transform(final_corpus) #extract features as well as perform vectorization\n",
    "print(cv.get_feature_names_out())\n",
    "print(X.toarray()) #dense matrix representation of vectors\n",
    "print(X)           #sparse matrix representation of vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef9927f6-463b-4be4-80c5-d95dfa573726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['food good good',\n",
       " 'food tasty',\n",
       " 'quality good',\n",
       " 'food not good',\n",
       " 'service poor',\n",
       " 'costly',\n",
       " 'cheap quality']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6000803-bd09-43c3-8c61-2c3ecb3b0524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cheap' 'costly' 'food' 'good' 'not' 'poor' 'quality' 'service' 'tasty']\n"
     ]
    }
   ],
   "source": [
    "cv=CountVectorizer(ngram_range=(1,1)) # In this situation model may be underfitted, due to too low features\n",
    "X=cv.fit_transform(final_corpus) #extract features as well as perform vectorization\n",
    "print(cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73d8c076-8516-485f-8f9d-19c4b733a884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cheap' 'cheap quality' 'costly' 'food' 'food good' 'food not'\n",
      " 'food tasty' 'good' 'good good' 'not' 'not good' 'poor' 'quality'\n",
      " 'quality good' 'service' 'service poor' 'tasty']\n"
     ]
    }
   ],
   "source": [
    "cv=CountVectorizer(ngram_range=(1,2))\n",
    "X=cv.fit_transform(final_corpus) #extract features as well as perform vectorization\n",
    "print(cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0aa8bb65-fd17-4b52-ad96-b2df82e48b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cheap quality' 'food good' 'food not' 'food tasty' 'good good'\n",
      " 'not good' 'quality good' 'service poor']\n"
     ]
    }
   ],
   "source": [
    "cv=CountVectorizer(ngram_range=(2,2))\n",
    "X=cv.fit_transform(final_corpus) #extract features as well as perform vectorization\n",
    "print(cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cf1d26b-c2f6-45a7-8bb1-cdb7eeadcffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cheap' 'cheap quality' 'costly' 'food' 'food good' 'food good good'\n",
      " 'food not' 'food not good' 'food tasty' 'good' 'good good' 'not'\n",
      " 'not good' 'poor' 'quality' 'quality good' 'service' 'service poor'\n",
      " 'tasty']\n"
     ]
    }
   ],
   "source": [
    "cv=CountVectorizer(ngram_range=(1,3)) # In this situation model may be overfitted, due to too many features\n",
    "X=cv.fit_transform(final_corpus) #extract features as well as perform vectorization\n",
    "print(cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77c5825b-24a2-4758-98cf-7c1619ffc47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cheap' 'food' 'food good' 'food good good' 'food not' 'food not good'\n",
      " 'food tasty' 'good' 'good good' 'not' 'not good' 'poor' 'quality'\n",
      " 'quality good' 'service']\n"
     ]
    }
   ],
   "source": [
    "cv=CountVectorizer(ngram_range=(1,3),max_features=15)\n",
    "X=cv.fit_transform(final_corpus) #extract features as well as perform vectorization\n",
    "print(cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92b641fc-996c-4ef8-a3d0-b219c122a4f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['food good good',\n",
       " 'food tasty',\n",
       " 'quality good',\n",
       " 'food not good',\n",
       " 'service poor',\n",
       " 'costly',\n",
       " 'cheap quality']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6685b0e3-ed86-46e8-a711-8424692a4a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['food' 'good']\n"
     ]
    }
   ],
   "source": [
    "cv=CountVectorizer(ngram_range=(1,3),max_features=None,min_df=3)\n",
    "X=cv.fit_transform(final_corpus) #extract features as well as perform vectorization\n",
    "print(cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10717d42-e72e-4a05-a010-212f6b7daa81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cheap' 'cheap quality' 'costly' 'food' 'food good' 'food good good'\n",
      " 'food not' 'food not good' 'food tasty' 'good' 'good good' 'not'\n",
      " 'not good' 'poor' 'quality' 'quality good' 'service' 'service poor'\n",
      " 'tasty']\n",
      "[[0 0 0 1 1 1 0 0 0 2 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0]\n",
      " [0 0 0 1 0 0 1 1 0 1 0 1 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "cv=CountVectorizer(ngram_range=(1,3),max_features=None,min_df=1)\n",
    "X=cv.fit_transform(final_corpus) #extract features as well as perform vectorization\n",
    "print(cv.get_feature_names_out())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4488e16e-650b-49d3-812b-388dcea31064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cheap' 'cheap quality' 'costly' 'food' 'food good' 'food good good'\n",
      " 'food not' 'food not good' 'food tasty' 'good' 'good good' 'not'\n",
      " 'not good' 'poor' 'quality' 'quality good' 'service' 'service poor'\n",
      " 'tasty']\n",
      "[[0 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0]\n",
      " [0 0 0 1 0 0 1 1 0 1 0 1 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "cv=CountVectorizer(ngram_range=(1,3),max_features=None,min_df=1,binary=True)\n",
    "# binary=True parameters are used for scaling, only show presence or abscence\n",
    "X=cv.fit_transform(final_corpus) #extract features as well as perform vectorization\n",
    "print(cv.get_feature_names_out())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "238d0ff8-1cf4-4e47-9b06-7aa109a42f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cheap' 'cheap quality' 'costly' 'food' 'food good' 'food good good'\n",
      " 'food not' 'food not good' 'food tasty' 'good' 'good good' 'not'\n",
      " 'not good' 'poor' 'quality' 'quality good' 'service' 'service poor'\n",
      " 'tasty']\n",
      "[[0 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0]\n",
      " [0 0 0 1 0 0 1 1 0 1 0 1 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "cv=CountVectorizer(ngram_range=(1,3),max_features=None,min_df=1,binary=True,\n",
    "                   lowercase=True,stop_words=sw)\n",
    "X=cv.fit_transform(final_corpus) #extract features as well as perform vectorization\n",
    "print(cv.get_feature_names_out())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b65bfb19-4b2c-4e56-a9d8-79d1335f3587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(doc):\n",
    "    doc=re.sub('[^a-zA-Z ]','',doc)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58beb8be-2623-4856-a2f3-743f6398343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_corpus=list(map(text_cleaning,corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5fefc144-ae5f-4c34-b329-e2abd20c7659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['food is  good  good',\n",
       " 'food is tasty',\n",
       " 'Quality is Good',\n",
       " 'food is not good',\n",
       " 'Service is poor',\n",
       " 'it is too costly',\n",
       " 'Cheap quality']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6b28e0d-d7ac-4a53-adca-204dde6f4f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cheap' 'cheap quality' 'costly' 'food' 'food good' 'food good good'\n",
      " 'food not' 'food not good' 'food tasty' 'good' 'good good' 'not'\n",
      " 'not good' 'poor' 'quality' 'quality good' 'service' 'service poor'\n",
      " 'tasty']\n",
      "[[0 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0]\n",
      " [0 0 0 1 0 0 1 1 0 1 0 1 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "cv=CountVectorizer(ngram_range=(1,3),max_features=None,min_df=1,binary=True,lowercase=True,\n",
    "                   stop_words=sw)\n",
    "X=cv.fit_transform(final_corpus) #extract features as well as perform vectorization\n",
    "print(cv.get_feature_names_out())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc11de89-fa40-47c0-ba12-3cee49806c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f0280c0-81d0-4ce9-98a2-12b2bd4719ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cheap' 'costly' 'food' 'good' 'not' 'poor' 'quality' 'service' 'tasty']\n",
      "[[0.         0.         0.4472136  0.89442719 0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.57866699 0.         0.         0.\n",
      "  0.         0.         0.81556393]\n",
      " [0.         0.         0.         0.64974959 0.         0.\n",
      "  0.76014832 0.         0.        ]\n",
      " [0.         0.         0.5008545  0.5008545  0.70589627 0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.70710678\n",
      "  0.         0.70710678 0.        ]\n",
      " [0.         1.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.76944876 0.         0.         0.         0.         0.\n",
      "  0.63870855 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#it is normalized version of countvectorizer\n",
    "tv=TfidfVectorizer(lowercase=True,stop_words=sw)\n",
    "X=tv.fit_transform(final_corpus) #extract features as well as perform vectorization\n",
    "print(tv.get_feature_names_out())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023a07f3-6d9c-41d3-ab77-f59167eee82a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2023e0c-9f98-47be-be35-17ccccf80b0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14cbac27-511f-4105-8851-dfa7e90eb857",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  Liked\n",
       "0                             Wow... Loved this place.      1\n",
       "1                                   Crust is not good.      0\n",
       "2            Not tasty and the texture was just nasty.      0\n",
       "3    Stopped by during the late May bank holiday of...      1\n",
       "4    The selection on the menu was great and so wer...      1\n",
       "..                                                 ...    ...\n",
       "995  I think food should have flavor and texture an...      0\n",
       "996                           Appetite instantly gone.      0\n",
       "997  Overall I was not impressed and would not go b...      0\n",
       "998  The whole experience was underwhelming, and I ...      0\n",
       "999  Then, as if I hadn't wasted enough of my life ...      0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"Restaurant_Reviews.tsv\",sep='\\t')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7b27953-ddd8-42f1-98f6-f794ae2e01ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus=df.Review\n",
    "target=df.Liked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aaacc3b9-534d-472e-95ff-cc330577dd04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_corpus=list(map(text_cleaning,corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c09c1339-e831-4c79-af0f-99ab05ef7e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB,BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bfeefd99-8a12-4ea3-a00f-183c857e4fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.956"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=CountVectorizer(lowercase=True,stop_words=sw)\n",
    "X=cv.fit_transform(final_corpus).toarray()\n",
    "y=target\n",
    "model=MultinomialNB() #best suitable with countvectorizer\n",
    "model.fit(X,y)\n",
    "model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "808ef719-73ab-4a64-ba00-209937782c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.945"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=TfidfVectorizer(lowercase=True,stop_words=sw)\n",
    "X=cv.fit_transform(final_corpus).toarray()\n",
    "y=target\n",
    "model=GaussianNB() #best suitable with tfidfvectrozer\n",
    "model.fit(X,y)\n",
    "model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2983583f-3aae-4651-9ed5-dc0155fb716c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.953"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=CountVectorizer(lowercase=True,stop_words=sw,binary=True)\n",
    "X=cv.fit_transform(final_corpus).toarray()\n",
    "y=target\n",
    "model=BernoulliNB() #best suitable with countvectorizer binary=True\n",
    "model.fit(X,y)\n",
    "model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8e80bb-b3ce-4497-bcba-41957daba70f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
